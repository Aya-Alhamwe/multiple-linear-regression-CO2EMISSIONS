# -*- coding: utf-8 -*-
"""MultipleLinearRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LKRcfyzkNxVFAwCePxyU9j819ox6jwbz

# **Machine Learning Project: Predicting CO2 Emissions using Multiple Linear Regression**

## Import Libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

"""## Load Data"""

url= "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%202/data/FuelConsumptionCo2.csv"

df = pd.read_csv(url)

"""## Data Overview"""

df.sample(5)

df.describe()

df.shape

"""# **Exploratory Data Analysis  and Visualization**

"""

# Drop categoricals and any unseless columns
df = df.drop(['MODELYEAR', 'MAKE', 'MODEL', 'VEHICLECLASS', 'TRANSMISSION', 'FUELTYPE',],axis=1)

"""#### Correlation matrix to explore relationships between features and CO2 emissions

"""

df.corr()

"""#### drop less useful features to keep only the most correlated ones

"""

df = df.drop(['CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB',],axis=1)

df.head(9)

"""#### Scatter matrix to visualize feature relationships

"""

axes = pd.plotting.scatter_matrix(df, alpha=0.2)

for ax in axes.flatten():
    ax.xaxis.label.set_rotation(90)
    ax.yaxis.label.set_rotation(0)
    ax.yaxis.label.set_ha('right')

plt.tight_layout()
plt.gcf().subplots_adjust(wspace=0, hspace=0)
plt.show()

"""# **Data Preprocessing**

#### Extract the input features and labels from the data set
"""

X = df.iloc[:, [0,1]].to_numpy()
y = df.iloc[:,[2]].to_numpy()

"""#### Standardize features to prevent bias from different magnitudes

"""

std_scaler = preprocessing.StandardScaler()
X_std = std_scaler.fit_transform(X)

"""#### Display statistical summary of standardized features

"""

pd.DataFrame(X_std).describe().round(2)

"""#### Create train and test datasets

"""

X_train, X_test, y_train, y_test = train_test_split(X_std,y,test_size=0.2,random_state=42)

"""# **Build a multiple linear regression model (Before Log Transform)**

"""

# create a model object
regressor = linear_model.LinearRegression()

# train the model in the training data
regressor.fit(X_train, y_train)

# Print the coefficients
coef_ =  regressor.coef_
intercept_ = regressor.intercept_

print ('Coefficients: ',coef_)
print ('Intercept: ',intercept_)

"""### Transform model coefficients back to the original feature scale

"""

# Get the standard scaler's mean and standard deviation parameters
means_ = std_scaler.mean_
std_devs_ = np.sqrt(std_scaler.var_)

# The least squares parameters can be calculated relative to the original, unstandardized feature space as:
coef_original = coef_ / std_devs_
intercept_original = intercept_ - np.sum((means_ * coef_) / std_devs_)

print ('Coefficients: ', coef_original)
print ('Intercept: ', intercept_original)

"""## **Evaluate Model Performance (Before Log Transform)**"""

y_pred = regressor.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
r2_percent = int(r2 * 100)

print('Evaluate Before Log Transform: ')
print(f"Mean absolute error: {mae:.2f}")
print(f"Mean squared error: {mse:.2f}")
print(f"Root mean squared error: {rmse:.2f}")
print(f"R2-score: {r2_percent}")

"""#### Plot actual vs predicted CO2 emissions for Engine Size and FUEL CONSUMPTION before log transform

"""

plt.figure(figsize=(8, 5))
plt.scatter(X_test[:, 0], y_test, color='blue', label='Actual')
plt.plot(X_test[:, 0], coef_[0][0] * X_test[:, 0] + intercept_[0], color='red', label='Predicted')
plt.xlabel("Engine Size")
plt.ylabel("CO2 Emissions")
plt.title("Prediction Before Log Transformation (Engine Size)")
plt.legend()
plt.savefig("prediction_before_log_engine.png", dpi=300)
plt.show()

plt.figure(figsize=(8, 5))
plt.scatter(X_test[:, 1], y_test, color='blue', label='Actual')
plt.plot(X_test[:, 1], coef_[0][1] * X_test[:, 1] + intercept_[0], color='red', label='Predicted')
plt.xlabel("FUELCONSUMPTION_COMB_MPG")
plt.ylabel("CO2 Emissions")
plt.title("Prediction Before Log Transformation (Fuel Consumption)")
plt.legend()
plt.savefig("prediction_before_log_fuel.png", dpi=300)
plt.show()

"""## **Log Transformation and Re-training**

### Log-transform and standardize features to stabilize variance and scale data
"""

X_log = np.log(X + 1e-6)

std_scaler_log = preprocessing.StandardScaler()
X_log_std = std_scaler_log.fit_transform(X_log)

"""### Split log-scaled data into training and test sets

"""

X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log_std, y, test_size=0.2, random_state=42)

"""###  Create and train the linear regression model on the log-transformed data

"""

regressor_log = linear_model.LinearRegression()
regressor_log.fit(X_train_log, y_train_log)

# Calculate model coefficients and intercept
means_log = std_scaler_log.mean_
std_devs_log = np.sqrt(std_scaler_log.var_)


coef_log = regressor_log.coef_
intercept_log = regressor_log.intercept_

coef_original_log = coef_log / std_devs_log
intercept_original_log = intercept_log - np.sum((means_log * coef_log) / std_devs_log)

print ('Coefficients with log transform:', coef_original_log)
print ('Intercept with log transform:', intercept_original_log)

"""# **Evaluate Model Performance (After Log Transform)**

#### Evaluate model errors and R2 (With Log Transformation)
"""

y_pred_log = regressor_log.predict(X_test_log)

mae_log = mean_absolute_error(y_test_log, y_pred_log)
mse_log = mean_squared_error(y_test_log, y_pred_log)
rmse_log = np.sqrt(mse_log)
r2_log = r2_score(y_test_log, y_pred_log)

print('Evaluate After Log Transform: ')
print(f"Mean absolute error: {mae_log:.2f}")
print(f"Mean squared error: {mse_log:.2f}")
print(f"Root mean squared error : {rmse_log:.2f}")
print(f"R2-score: {r2_log:.2f}")

plt.figure(figsize=(8, 5))
plt.scatter(X_test_log[:, 0], y_test_log, color='blue', label='Actual')
plt.plot(X_test_log[:, 0], coef_log[0] * X_test_log[:, 0] + intercept_log, color='red', label='Predicted')
plt.xlabel("log(Engine Size)")
plt.ylabel("CO2 Emissions")
plt.title("Prediction After Log Transformation (Engine Size)")
plt.legend()
plt.savefig("prediction_after_log_engine.png", dpi=300)
plt.show()

plt.figure(figsize=(8, 5))
plt.scatter(X_test_log[:, 1], y_test_log, color='blue', label='Actual')
plt.plot(X_test_log[:, 1], coef_log[1] * X_test_log[:, 1] + intercept_log, color='red', label='Predicted')
plt.xlabel("log(FUELCONSUMPTION_COMB_MPG)")
plt.ylabel("CO2 Emissions")
plt.title("Prediction After Log Transformation (Fuel Consumption)")
plt.legend()
plt.savefig("prediction_after_log_fuel.png", dpi=300)
plt.show()

"""#  **Model Evaluation using Cross-Validation**

"""

# Apply log transform to the features
X_log = np.log(X + 1e-6)
y = y.ravel()

# 2 Standardize the log-transformed features
scaler = StandardScaler()
X_log_std = scaler.fit_transform(X_log)

# Create the model
model = LinearRegression()

# 4. Perform 5-fold cross-validation using R² as the metric
scores = cross_val_score(model, X_log_std, y, cv=5, scoring='r2')

print("Cross-Validation:")
print("R² scores for each fold:", scores)
print("Average R²:", np.mean(scores))